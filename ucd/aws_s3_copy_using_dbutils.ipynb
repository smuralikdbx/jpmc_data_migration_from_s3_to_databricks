{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15500d6-95a7-4738-b9c6-26078bc25121",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import concurrent.futures\n",
    "import os\n",
    "import time\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed,ThreadPoolExecutor\n",
    "from multiprocessing import cpu_count\n",
    "import threading\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28cb9d8f-6677-4eaf-8602-4de4f5fccdc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"root_src_folder\", \"s3://databricks-e2demofieldengwest/dom_rodrigues/folder_1/\", \"Source folder\") \n",
    "#dbfs:/tmp/dom3\n",
    "dbutils.widgets.text(\"root_dest_folder\", \"s3://databricks-e2demofieldengwest/dom_rodrigues/folder_2/\", \"Destination Folder\") \n",
    "#dbfs:/tmp/dom4\n",
    "\n",
    "dbutils.widgets.text(\"max_workers\", \"4\", \"Max Workers\")\n",
    "dbutils.widgets.text(\"dbutils_thread_pool_size\", \"80\", \"DBUtils Thread Pool Size\")\n",
    "\n",
    "dbutils.widgets.dropdown(\"fileCopyDepthLevel\", \"3\", [\"2\", \"3\"],  \"Starting Folder Copy Level\")\n",
    "dbutils.widgets.dropdown(\"use_parallel_notebooks\", \"False\", [\"True\", \"False\"], \"Use Parallel Notebooks instead of threads\")\n",
    "\n",
    "dbutils.widgets.dropdown(\"debug\", \"True\", [\"True\", \"False\"], \"Debug\")\n",
    "\n",
    "dbutils.widgets.text(\"runId\", \"\")\n",
    "runId =  dbutils.widgets.get(\"runId\")\n",
    "runId = str(uuid.uuid4()) if len(runId.strip()) == 0 else runId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c9b4286-76db-4627-9b64-4c58276d56e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "root_src_folder =dbutils.widgets.get(\"root_src_folder\")\n",
    "root_dest_folder = dbutils.widgets.get(\"root_dest_folder\")\n",
    "debug = True if dbutils.widgets.get(\"debug\") == \"True\" else False\n",
    "use_parallel_notebooks = True if dbutils.widgets.get(\"use_parallel_notebooks\") == \"True\" else False\n",
    "\n",
    "fileCopyDepthLevel = int(dbutils.widgets.get(\"fileCopyDepthLevel\")) #(root, folderLevel1, folderLevel11)\n",
    "max_workers = int(dbutils.widgets.get(\"max_workers\"))\n",
    "dbutils_thread_pool_size  = int(dbutils.widgets.get(\"dbutils_thread_pool_size\"))\n",
    "\n",
    "trace=False\n",
    "generateTestData=False\n",
    "\n",
    "if root_src_folder == root_dest_folder:\n",
    "    raise Exception(\"Source and Destination folders cannot be the same\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2bfa0b-092e-4f52-8c45-af7665b440d4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Enable dbutils experimental feature"
    }
   },
   "outputs": [],
   "source": [
    "# The operation is parallelized by first recursively listing the objects in the source directory using a thread pool on the driver and subsequently launching a Spark job to perform the individual operations.\n",
    "\n",
    "spark.conf.set(\"spark.databricks.service.dbutils.fs.parallel.enabled\", True)\n",
    "spark.conf.set(\"spark.databricks.service.dbutils.fs.parallel.ls.threadPoolSize\", dbutils_thread_pool_size) #default 20\n",
    "#spark.conf.set(\"spark.databricks.service.dbutils.fs.parallel.ls.timeoutSeconds\", 7200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc17e10-3ff3-44de-bd79-64aaab056b54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Generate Test Data to Validate file and folder list generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "444a030f-706e-46cb-9a4e-93c4fe7425bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Test Data"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if generateTestData:\n",
    "    dbutils.fs.mkdirs(root_src_folder)\n",
    "\n",
    "    #csv file folder at root filer\n",
    "    data = [(\"Apple\", 10), (\"Banana\", 20), (\"Orange\", 30)]\n",
    "    columns = [\"Fruit\", \"Quantity\"]\n",
    "    df = spark.createDataFrame(data, columns)\n",
    "    df.write.mode(\"overwrite\").csv(f\"{root_src_folder}/a.csv\")\n",
    "\n",
    "    #parquet file folder  at root folder\n",
    "    single_partition_df = df.coalesce(1)\n",
    "    output_path = \"output_single.parquet\"\n",
    "    single_partition_df.write.mode(\"overwrite\").parquet(f\"{root_src_folder}/p.parquet\")\n",
    "\n",
    "    #empty subfolder at two levels\n",
    "    dbutils.fs.mkdirs(f\"{root_src_folder}/folder1/folder11\")\n",
    "\n",
    "    #empty subfolder at three levels\n",
    "    dbutils.fs.mkdirs(f\"{root_src_folder}/folder1/folder11/folder111\")\n",
    "\n",
    "    #empty subfolder at fourth levels\n",
    "    dbutils.fs.mkdirs(f\"{root_src_folder}/folder1/folder11/folder111/folder1111\")\n",
    "\n",
    "    #file at folder2 folder\n",
    "    single_partition_df.write.mode(\"overwrite\").parquet(f\"{root_src_folder}/folder2/p.parquet\")\n",
    "\n",
    "    #filparquet file folder e at folder3 folder and empty folder folder31\n",
    "    dbutils.fs.mkdirs(f\"{root_src_folder}/folder1/folder3/folder31\")\n",
    "    single_partition_df.write.mode(\"overwrite\").parquet(f\"{root_src_folder}/folder3/p.parquet\")\n",
    "\n",
    "    # parquet file folder at folder41 folder \n",
    "    single_partition_df.write.mode(\"overwrite\").parquet(f\"{root_src_folder}/folder4/folder41/p.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9ba3a38d-d192-450a-8d4d-06e69bbea6fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "View test data"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(f\"{root_src_folder}/p.parquet\") if generateTestData else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c44a35ba-8cee-4805-be5f-8f8c081237da",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test data using parquet file"
    }
   },
   "outputs": [],
   "source": [
    "if generateTestData:\n",
    "    parquet_single_file=f\"{root_src_folder}/p.parquet/part-00000-tid-3071788195048556433-4a9763e1-4acc-4310-b8b1-55d68c23f923-33-1.c000.snappy.parquet\"\n",
    "    dbutils.fs.ls(parquet_single_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "db6e8f42-32a7-4cfe-8227-cee5bf5c6199",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "More test data using files"
    }
   },
   "outputs": [],
   "source": [
    "if generateTestData:\n",
    "\n",
    "    #root_level\n",
    "    dbutils.fs.cp(parquet_single_file, f\"{root_src_folder}/level1.parquet\")\n",
    "\n",
    "    #at level 3\n",
    "    dbutils.fs.cp(parquet_single_file, f\"{root_src_folder}/folder5/level2.parquet\")\n",
    "\n",
    "    #at level 3\n",
    "    dbutils.fs.cp(parquet_single_file, f\"{root_src_folder}/folder6/folder61/level3.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c5cfeb2-4e20-45d4-965d-d507ad242040",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### File and Folder List Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "802c7803-d162-42dd-9eb2-cca6dacb90ba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Make destination folder if it does not exists"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(f\"{root_src_folder}\") if debug else None\n",
    "try:\n",
    "    dbutils.fs.ls(f\"{root_dest_folder}\") if debug else None \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"creating new destination folder {root_dest_folder}\")\n",
    "    dbutils.fs.mkdirs(root_dest_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e68c4b5-17f2-47ea-8dda-85a65f5c09b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Collects path at root (first) and second level"
    }
   },
   "outputs": [],
   "source": [
    "def collect_paths_at_second_level(base_path):\n",
    "    # Track second-level files and first-level files/folders (without overlap)\n",
    "    level_1 = dbutils.fs.ls(base_path)\n",
    "    paths_to_copy = []\n",
    "    filenames = set()\n",
    "\n",
    "    if len(level_1) == 0:\n",
    "        paths_to_copy.append({'path': base_path,  'type': 'dir', 'size': 0}) \n",
    "    else:    \n",
    "        for item in level_1:\n",
    "            if item.isDir():\n",
    "                subitems = dbutils.fs.ls(item.path)\n",
    "                # Only add sub-items (files and folders) at second level\n",
    "                if len(subitems) == 0:\n",
    "                    paths_to_copy.append({'path': item.path,  'type': 'dir', 'size': item.size}) \n",
    "                else:\n",
    "                    for subitem in subitems:\n",
    "                        paths_to_copy.append({'path': subitem.path, 'type': 'dir' if subitem.isDir() else 'file','size': subitem.size})\n",
    "                        filenames.add(subitem.path)\n",
    "            else:\n",
    "                paths_to_copy.append({'path': item.path, 'type': 'file', 'size': item.size})\n",
    "                filenames.add(item.path)\n",
    "    return paths_to_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dc2a2ee-7882-4738-85d4-bbccf07a4f19",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Root Level and subfolder at root level"
    }
   },
   "outputs": [],
   "source": [
    "paths_to_copy = collect_paths_at_second_level(f\"{root_src_folder}\")\n",
    "\n",
    "paths_to_copy_pd_df = pd.DataFrame(paths_to_copy)\n",
    "paths_to_copy_pd_df_files = paths_to_copy_pd_df[paths_to_copy_pd_df['type'] == 'file']\n",
    "paths_to_copy_pd_df_dirs = paths_to_copy_pd_df[paths_to_copy_pd_df['type'] == 'dir']\n",
    "\n",
    "print(paths_to_copy_pd_df_files.sort_values(by='path')) if trace else None\n",
    "print(paths_to_copy_pd_df_dirs.sort_values(by='path')) if trace else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ebf6bc-6303-4dc7-93a5-92752c8d6463",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add third level folders file"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if fileCopyDepthLevel == 3:\n",
    "    new_paths_to_copy_pd_df_files = pd.DataFrame(columns=paths_to_copy_pd_df_files.columns)\n",
    "    new_paths_to_copy_pd_df_dirs = pd.DataFrame(columns=paths_to_copy_pd_df_dirs.columns)\n",
    "\n",
    "    new_paths_to_copy_pd_df_files = pd.concat([paths_to_copy_pd_df_files, new_paths_to_copy_pd_df_files], ignore_index=True, axis=0)\n",
    "\n",
    "    for row in paths_to_copy_pd_df_dirs.itertuples(index=False):  # index=False if you don't need the index\n",
    "        new_paths_df = collect_paths_at_second_level(row.path)\n",
    "        new_paths_to_copy_pd_df = pd.DataFrame(new_paths_df)\n",
    "        #AdAppend new files\n",
    "        new_paths_to_copy_pd_df_files = pd.concat([new_paths_to_copy_pd_df_files, new_paths_to_copy_pd_df[new_paths_to_copy_pd_df['type'] == 'file']], ignore_index=True, axis=0)\n",
    "        #Append new dirs\n",
    "        new_paths_to_copy_pd_df_dirs = pd.concat([new_paths_to_copy_pd_df_dirs, new_paths_to_copy_pd_df[new_paths_to_copy_pd_df['type'] == 'dir']], ignore_index=True, axis=0)\n",
    "else:\n",
    "    new_paths_to_copy_pd_df_files =  paths_to_copy_pd_df_files\n",
    "    new_paths_to_copy_pd_df_dirs =  paths_to_copy_pd_df_dirs       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "300b46ed-b508-42ef-a38b-84d60218cc49",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "At Level 2 (original)"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"file count {paths_to_copy_pd_df_files.shape[0]}\") if trace else None\n",
    "print(f\"dir count {paths_to_copy_pd_df_dirs.shape[0]}\") if trace else None\n",
    "\n",
    "print(paths_to_copy_pd_df_files.sort_values(by='path')) if trace else None\n",
    "print(paths_to_copy_pd_df_dirs.sort_values(by='path')) if trace else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b5c4a990-ec50-464b-b767-39875b825e46",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "At Level 3"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"file count {new_paths_to_copy_pd_df_files.shape[0]}\") if trace else None\n",
    "print(f\"dir count {new_paths_to_copy_pd_df_dirs.shape[0]}\") if trace else None\n",
    "\n",
    "print(new_paths_to_copy_pd_df_files.sort_values(by='path')) if trace else None\n",
    "print(new_paths_to_copy_pd_df_dirs.sort_values(by='path')) if trace else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "512778da-51ee-4627-9a01-0296e531eb65",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "merge and create dest folder"
    }
   },
   "outputs": [],
   "source": [
    "new_paths_to_copy_pd_df_all = pd.concat([new_paths_to_copy_pd_df_files, new_paths_to_copy_pd_df_dirs]) \n",
    "\n",
    "new_paths_to_copy_pd_df_all['dest_path'] = new_paths_to_copy_pd_df_all['path'].str.replace(root_src_folder, root_dest_folder, regex=False)\n",
    "\n",
    "new_paths_to_copy_pd_df_all['src_dest_tuple']  = new_paths_to_copy_pd_df_all[['path', 'dest_path']].apply(tuple, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae771181-b002-4c51-8f34-22ef3ed142e1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Test files to copy or build actual list"
    }
   },
   "outputs": [],
   "source": [
    "if generateTestData:\n",
    "    all_files = []\n",
    "    all_files.append((\"dbfs:/tmp/dom3/folder5/level2.parquet\", \"dbfs:/tmp/dom4/folder5/level2.parquet\"))\n",
    "    all_files.append((\"dbfs:/tmp/dom3/folder6/folder61/level3.parquet\", \"dbfs:/tmp/dom4/folder6/folder61/level3.parquet\"))\n",
    "    all_files.append((\"dbfs:/tmp/dom3/folder5/level2.parquet\", \"dbfs:/tmp/dom4/folder5/level2.parquet\"))\n",
    "    # Add file indices for better tracking\n",
    "    indexed_files = [(src_path, dest_path, i+1, type, len(all_files)) for i, (src_path, dest_path) in enumerate(all_files)]\n",
    "\n",
    "else:\n",
    "    indexed_files = [(row['path'], row['dest_path'], row['type'], i+1, new_paths_to_copy_pd_df_all.shape[0]) for i, row in enumerate(new_paths_to_copy_pd_df_all.to_records(index=False))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "75b247b5-1432-463d-8d7e-2faa2312c12d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Test s3 copy file"
    }
   },
   "outputs": [],
   "source": [
    "#indexed_files = indexed_files[:2]\n",
    "#print(indexed_files[:1]) if debug else None\n",
    "#dbutils.fs.cp(indexed_files[0][0], indexed_files[0][1], recurse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "718b74de-0457-486d-ad10-a7904b764cd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Actual copy process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce94fc0f-7ee3-4033-b0bd-a061f865fe9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDEA8 FILE COPY : 284 files using 4 cores...\n\uD83D\uDCCA Progress will be reported every 1 minute...\n\uD83D\uDD14 Each file or folder completion will be reported immediately with timing...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if generateTestData:\n",
    "    print(f\"\\n\uD83D\uDEA8 FILE COPY : {len(all_files)} files using {max_workers} cores...\")\n",
    "else:    \n",
    "    print(f\"\\n\uD83D\uDEA8 FILE COPY : {new_paths_to_copy_pd_df_all.shape[0]} files using {max_workers} cores...\")\n",
    "print(\"\uD83D\uDCCA Progress will be reported every 1 minute...\")\n",
    "print(\"\uD83D\uDD14 Each file or folder completion will be reported immediately with timing...\")\n",
    "\n",
    "def progress_monitor(futures_dict, total_files, max_workers):\n",
    "    \"\"\"Monitor progress with ACCURATE running count\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        time.sleep(60)  # Check every 1 minute\n",
    "        \n",
    "        completed = sum(1 for f in futures_dict.keys() if f.done())\n",
    "        \n",
    "        # CORRECT way to calculate running tasks\n",
    "        actually_running = min(max_workers, total_files - completed)\n",
    "        pending = total_files - completed - actually_running\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        if completed > 0:\n",
    "            avg_time = elapsed / completed\n",
    "            remaining_estimate = (total_files - completed) * avg_time / max_workers / 60\n",
    "            print(f\"\uD83D\uDCCA Progress: {completed}/{total_files} completed, {actually_running} actively running, {pending} pending, ~{remaining_estimate:.1f}min remaining\")\n",
    "        else:\n",
    "            print(f\"\uD83D\uDCCA Progress: {completed}/{total_files} completed, {actually_running} actively running, {pending} pending, {elapsed/60:.1f}min elapsed\")\n",
    "            # If nothing completed after 5+ minutes, likely hanging\n",
    "            if elapsed > 300:\n",
    "                print(\"⚠️  WARNING: No files completed in 5+ minutes - processes may be hanging!\")\n",
    "        \n",
    "        if completed == total_files:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5ff6ace-2f29-4d11-a294-aef810b8f586",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "copy files using same noteboo"
    }
   },
   "outputs": [],
   "source": [
    "def copy_files(args):\n",
    "    start_time = time.time()\n",
    "    src_path, dest_path, file_type, file_index, total_files_len = args\n",
    "\n",
    "    print(f\"ThreadId {threading.get_native_id()}: copying src {src_path}\\n\") if trace else None\n",
    "    try: \n",
    "        dbutils.fs.cp(src_path, dest_path, recurse=True if file_type == 'dir' else False)\n",
    "        return {\"status\": \"SUCCESS\",\"duration\": time.time() -start_time}\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e}\")\n",
    "        return {\"status\": \"FAILED\",\"duration\": time.time() -start_time}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77883901-cb61-4a75-8e32-f68cc990a1f9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Copy files using parallel notebooks"
    }
   },
   "outputs": [],
   "source": [
    "cwd = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "notebook_path = \"/Workspace\" + cwd + \"/../s3_copy_worker_notebook\"\n",
    "\n",
    "def copy_files_using_parallel_notebooks(args):\n",
    "    start_time = time.time()\n",
    "    src_path, dest_path, file_type, file_index, total_files_len = args\n",
    "    notebook_parameters = {\"src_path\": src_path, \"dest_path\": dest_path, \"file_type\": file_type, \\\n",
    "        \"file_index\": file_index, \"total_files_len\": total_files_len, \"dbutils_thread_pool_size\": dbutils_thread_pool_size}\n",
    "                           \n",
    "    try: \n",
    "        returned_value =  dbutils.notebook.run(notebook_path, 0, notebook_parameters)\n",
    "        print(f\"notebook return value {returned_value }\") if debug else None\n",
    "        return {\"status\": \"SUCCESS\",\"duration\": time.time() -start_time}\n",
    "    except Exception as e:\n",
    "        print(f\"Exception {e}\")\n",
    "        return {\"status\": \"FAILED\",\"duration\": time.time() -start_time}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f53afb-5223-448b-892f-db4a966c4be8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Using Pools for IO Operation"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Progress: 282/284 completed, 2 actively running, 0 pending, ~0.0min remaining\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:    \n",
    "    # Submit all tasks\n",
    "    if use_parallel_notebooks == True:\n",
    "        futures_dict = {executor.submit(copy_files_using_parallel_notebooks, file_data): file_data \n",
    "                for file_data in indexed_files}\n",
    "    else:\n",
    "        futures_dict = {executor.submit(copy_files, file_data): file_data \n",
    "           for file_data in indexed_files}    \n",
    "\n",
    "    # Start progress monitor with correct max_workers\n",
    "    progress_thread = threading.Thread(target=progress_monitor, args=(futures_dict, len(indexed_files), max_workers))\n",
    "    progress_thread.daemon = True\n",
    "    progress_thread.start()\n",
    "    \n",
    "    completed = 0\n",
    "    converted = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Process results with 10 minute timeout per file\n",
    "    for future in as_completed(futures_dict, timeout=None):\n",
    "        completed += 1\n",
    "        \n",
    "        try:\n",
    "            result = future.result(timeout=600)  # 10 minute timeout\n",
    "            \n",
    "            # Extract timing information and print completion notice\n",
    "            file_data = futures_dict[future]\n",
    "            src_path, dest_path, file_type, file_index, all_files_len = file_data\n",
    "            if  result[\"status\"] == \"SUCCESS\":\n",
    "                converted += 1\n",
    "                # Extract time from result (it's in format \"filename (X.Xs)\")\n",
    "                time_part = result[\"duration\"]\n",
    "                print(f\"✅ COMPLETED [{completed}/{all_files_len}]: {src_path} - {time_part}\") if trace else None\n",
    "            elif  result[\"status\"] == \"FAILED\":\n",
    "                failed += 1\n",
    "                print(f\"❌ FAILED [{completed}/{all_files_len}]: {src_path}\")\n",
    "            elif   result[\"status\"] == \"SKIPPED\":\n",
    "                print(f\"⏭️ SKIPPED [{completed}/{all_files_len}]: {src_path} (already exists)\")\n",
    "            \n",
    "        except concurrent.futures.TimeoutError as e1:\n",
    "            print(f\"TimeoutError Exception: {e1}\")\n",
    "            failed += 1\n",
    "            file_data = futures_dict[future]\n",
    "            src_path, dest_path, file_type, file_index, all_files_len = file_data\n",
    "            print(f\"❌ TIMEOUT [{completed}/{all_files_len}]: {src_path} - took >10min\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "            failed += 1\n",
    "            file_data = futures_dict[future]\n",
    "            \n",
    "            src_path, dest_path, file_type, file_index, all_files_len = file_data\n",
    "            print(f\"❌ ERROR [{completed}/{all_files_len}]: {src_path} - {str(e)[:50]}...\")\n",
    "\n",
    "total_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67a6aa68-6a95-4b37-849d-e75cb0185ea5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCA Total time: 117.9 seconds (2.0 minutes)\n\uD83D\uDCCA Average per copied file (or folder): 0.4 seconds\n\uD83D\uDCCA Copy rate: 144.6 files (or folders)/minute\n\uD83D\uDCCA Results: 284 copied, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(f\"\uD83D\uDCCA Total time: {total_time:.1f} seconds ({total_time/60:.1f} minutes)\")\n",
    "if converted > 0:\n",
    "    print(f\"\uD83D\uDCCA Average per copied file (or folder): {total_time/converted:.1f} seconds\")\n",
    "    print(f\"\uD83D\uDCCA Copy rate: {converted/(total_time/60):.1f} files (or folders)/minute\")\n",
    "print(f\"\uD83D\uDCCA Results: {converted} copied, {failed} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1cf88e7-f164-4d5d-a3c1-c834d060c5ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(f\"{root_dest_folder}\") if trace else None"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "aws_s3_copy_using_dbutils",
   "widgets": {
    "dbutils_thread_pool_size": {
     "currentValue": "80",
     "nuid": "bab59760-b742-44eb-af9e-7417496a1948",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "80",
      "label": "DBUtils Thread Pool Size",
      "name": "dbutils_thread_pool_size",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "80",
      "label": "DBUtils Thread Pool Size",
      "name": "dbutils_thread_pool_size",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "debug": {
     "currentValue": "True",
     "nuid": "fc8871be-7187-409f-bad7-3eadafbf22f7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "True",
      "label": "Debug",
      "name": "debug",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "True",
        "False"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "True",
      "label": "Debug",
      "name": "debug",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "True",
        "False"
       ]
      }
     }
    },
    "fileCopyDepthLevel": {
     "currentValue": "2",
     "nuid": "488d3654-8673-485e-af33-dcc21b341d1b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "3",
      "label": "Starting Folder Copy Level",
      "name": "fileCopyDepthLevel",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "2",
        "3"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "3",
      "label": "Starting Folder Copy Level",
      "name": "fileCopyDepthLevel",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "2",
        "3"
       ]
      }
     }
    },
    "max_workers": {
     "currentValue": "8",
     "nuid": "3cdb4ae5-694b-4498-8349-ebec1a2e3e8d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "4",
      "label": "Max Workers",
      "name": "max_workers",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "4",
      "label": "Max Workers",
      "name": "max_workers",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "root_dest_folder": {
     "currentValue": "s3://databricks-e2demofieldengwest/dom_rodrigues/folder_2/",
     "nuid": "34435e02-22f6-4360-8824-32707f3daa42",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "s3://databricks-e2demofieldengwest/dom_rodrigues/folder_2/",
      "label": "Destination Folder",
      "name": "root_dest_folder",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://databricks-e2demofieldengwest/dom_rodrigues/folder_2/",
      "label": "Destination Folder",
      "name": "root_dest_folder",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "root_src_folder": {
     "currentValue": "s3://databricks-e2demofieldengwest/dom_rodrigues/folder_1/",
     "nuid": "bcc02e5e-d27f-46d7-9910-19e7e483967a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "s3://databricks-e2demofieldengwest/dom_rodrigues/folder_1/",
      "label": "Source folder",
      "name": "root_src_folder",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "s3://databricks-e2demofieldengwest/dom_rodrigues/folder_1/",
      "label": "Source folder",
      "name": "root_src_folder",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "runId": {
     "currentValue": "",
     "nuid": "4145b582-645a-4521-bffd-1baa5549e2b0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "runId",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "runId",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "use_parallel_notebooks": {
     "currentValue": "False",
     "nuid": "c6e2a5b1-a7dc-49cb-890c-7c9f43738c98",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "False",
      "label": "Use Parallel Notebooks instead of threads",
      "name": "use_parallel_notebooks",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "True",
        "False"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "False",
      "label": "Use Parallel Notebooks instead of threads",
      "name": "use_parallel_notebooks",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "True",
        "False"
       ]
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}